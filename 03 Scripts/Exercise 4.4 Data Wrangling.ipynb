{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36627fa5-1ea8-48df-ac3e-c1b0334bb8a0",
   "metadata": {},
   "source": [
    "# Exercise 4.4: Data Wrangling & Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089a8ec-ca7c-4bf0-a73d-d6d07bc8808d",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. Setup and Libraries\n",
    "2. Data Import\n",
    "3. Convert Identifier Variable to String\n",
    "4. Rename an Unlabeled Column\n",
    "5. Find the Busiest Hour for Placing Orders\n",
    "6. Determine the Meaning of Department ID 4\n",
    "7. Create a Subset for Breakfast Items\n",
    "8. Create a Subset for Dinner Party Items\n",
    "9. Count Rows in the Last Subset\n",
    "10. Extract Information About a Specific User\n",
    "11. Analyze User Behavior for User ID = 1\n",
    "12. Summary of Findings\n",
    "13. Export Subsets as Pickle and CSV Files\n",
    "14. Update the Final Dataset\n",
    "15. Reinspect the Data\n",
    "16. Unite Two Dataframes\n",
    "17. Export the Updated Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c39ea13-b592-42cb-b5fe-99ca00ed0afa",
   "metadata": {},
   "source": [
    "## Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c15e871-9174-4cc1-9b72-8be7bb5b6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a82d6d-12aa-4172-bc0f-ac14401365d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4a67e40-259f-44b8-9ddd-ea81636fc591",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4cc09fee-c396-4ecc-8595-8ca1bce95676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project path\n",
    "path = r'C:\\Users\\Ripple\\Desktop\\YVC\\Data Analytics (CF)\\Python Fundamentals for Data Analysts\\Instacart Basket Analysis'\n",
    "\n",
    "# Load datasets\n",
    "df_ords = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'orders.csv'))\n",
    "df_prods = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'products.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "177b1284-48a5-4ecb-a18b-1a5cd446a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2398795        1    prior             2          3                  7   \n",
      "2    473747        1    prior             3          3                 12   \n",
      "3   2254736        1    prior             4          4                  7   \n",
      "4    431534        1    prior             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  \n",
      "0                     NaN  \n",
      "1                    15.0  \n",
      "2                    21.0  \n",
      "3                    29.0  \n",
      "4                    28.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3421083 entries, 0 to 3421082\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   order_id                int64  \n",
      " 1   user_id                 int64  \n",
      " 2   eval_set                object \n",
      " 3   order_number            int64  \n",
      " 4   order_dow               int64  \n",
      " 5   order_hour_of_day       int64  \n",
      " 6   days_since_prior_order  float64\n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 182.7+ MB\n",
      "None\n",
      "   product_id                                       product_name  aisle_id  \\\n",
      "0           1                         Chocolate Sandwich Cookies        61   \n",
      "1           2                                   All-Seasons Salt       104   \n",
      "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
      "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
      "4           5                          Green Chile Anytime Sauce         5   \n",
      "\n",
      "   department_id  prices  \n",
      "0             19     5.8  \n",
      "1             13     9.3  \n",
      "2              7     4.5  \n",
      "3              1    10.5  \n",
      "4             13     4.3  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49693 entries, 0 to 49692\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   product_id     49693 non-null  int64  \n",
      " 1   product_name   49677 non-null  object \n",
      " 2   aisle_id       49693 non-null  int64  \n",
      " 3   department_id  49693 non-null  int64  \n",
      " 4   prices         49693 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check orders dataset\n",
    "print(df_ords.head())\n",
    "print(df_ords.info())\n",
    "\n",
    "# Check products dataset\n",
    "print(df_prods.head())\n",
    "print(df_prods.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dfa245-9a40-4a49-8a72-b97ec60b0e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fba89606-731d-4149-8ee1-bb724900d20d",
   "metadata": {},
   "source": [
    "## Convert Identifier Variable to String"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b632f4-5975-411f-8a32-e758f91a56a3",
   "metadata": {},
   "source": [
    "2. Find another identifier variable in the df_ords dataframe that doesn’t need to be included in your analysis as a numeric variable and change it to a suitable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8cbe43a5-cd09-4d1f-b0c3-23ecae925cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "# Convert order_id to a string\n",
    "df_ords['order_id'] = df_ords['order_id'].astype('str')\n",
    "\n",
    "# Verify the change\n",
    "print(df_ords['order_id'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed86c3-0d8e-4a31-a5b7-e14fed14acbc",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I changed the `order_id` column from an integer to a string because it’s just an identifier and doesn’t need to be analyzed numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d2d70-4010-4ba2-a89c-338ae4f7a670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9fa99ea-bb66-46be-a18a-009dcad0dac5",
   "metadata": {},
   "source": [
    "## Rename an Unintuitive Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc939d-cf12-4130-9bbd-e605832db5ec",
   "metadata": {},
   "source": [
    "3. Look for a variable in your df_ords dataframe with an unintuitive name and change its name without overwriting the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6b9dd788-cfe8-4c38-b7c9-ca26b20148d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_day_of_week  \\\n",
      "0   2539329        1    prior             1                  2   \n",
      "1   2398795        1    prior             2                  3   \n",
      "2    473747        1    prior             3                  3   \n",
      "3   2254736        1    prior             4                  4   \n",
      "4    431534        1    prior             5                  4   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  \n",
      "0                  8                     NaN  \n",
      "1                  7                    15.0  \n",
      "2                 12                    21.0  \n",
      "3                  7                    29.0  \n",
      "4                 15                    28.0  \n"
     ]
    }
   ],
   "source": [
    "# Rename order_dow to order_day_of_week\n",
    "df_ords.rename(columns={'order_dow': 'order_day_of_week'}, inplace=True)\n",
    "\n",
    "# Verify the change\n",
    "print(df_ords.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce2bd4-af5f-4192-86f0-80b8af9008f0",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I renamed the `order_dow` column to `order_day_of_week` to make it clearer and easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa03621-5b5b-49d8-8bf9-fece8985c7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602bcbbb-9325-4833-851d-bdc6835a8415",
   "metadata": {},
   "source": [
    "## Find the Busiest Hour for Placing Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05468d43-0c23-4d4a-bbb0-1fac9e0ad9ee",
   "metadata": {},
   "source": [
    "4. Your client wants to know what the busiest hour is for placing orders. Find the frequency of the corresponding variable and share your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d5d77658-bfe0-4157-91de-5c0c52140384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_hour_of_day\n",
      "0      22758\n",
      "1      12398\n",
      "2       7539\n",
      "3       5474\n",
      "4       5527\n",
      "5       9569\n",
      "6      30529\n",
      "7      91868\n",
      "8     178201\n",
      "9     257812\n",
      "10    288418\n",
      "11    284728\n",
      "12    272841\n",
      "13    277999\n",
      "14    283042\n",
      "15    283639\n",
      "16    272553\n",
      "17    228795\n",
      "18    182912\n",
      "19    140569\n",
      "20    104292\n",
      "21     78109\n",
      "22     61468\n",
      "23     40043\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frequency of each hour\n",
    "busiest_hours = df_ords['order_hour_of_day'].value_counts()\n",
    "\n",
    "# Sort the values to find the busiest hour\n",
    "busiest_hours_sorted = busiest_hours.sort_index()\n",
    "\n",
    "# Display the results\n",
    "print(busiest_hours_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712b412-1cd4-4d33-b8b1-2c80da728de7",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I looked at the `order_hour_of_day` column and found that **10 AM** is the busiest hour, with **283,728 orders**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e97042-bf35-474e-822f-45de8953941e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf54df22-84ae-4847-91eb-2816945e7947",
   "metadata": {},
   "source": [
    "## Determine the Meaning of Department ID 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f901f8f-c736-42f1-a03e-e1f08941a8d4",
   "metadata": {},
   "source": [
    "5. Determine the meaning behind a value of 4 in the department_id column within the df_prods dataframe using a data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ad6a97a0-79dd-4720-a9af-126d8af22c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product_id                    product_name  aisle_id  department_id  \\\n",
      "30          31              White Pearl Onions       123              4   \n",
      "42          43             Organic Clementines       123              4   \n",
      "44          45               European Cucumber        83              4   \n",
      "65          66       European Style Spring Mix       123              4   \n",
      "88          89  Yogurt Fruit Dip Sliced Apples       123              4   \n",
      "\n",
      "    prices  \n",
      "30     7.5  \n",
      "42    11.5  \n",
      "44    14.3  \n",
      "65    11.7  \n",
      "88    12.6  \n"
     ]
    }
   ],
   "source": [
    "# Check the unique values in the department_id column\n",
    "department_4 = df_prods[df_prods['department_id'] == 4]\n",
    "\n",
    "# Display the result\n",
    "print(department_4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d750c-ef5f-4b64-9618-d5e532200557",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I filtered `df_prods` and found that **department ID 4** represents **breakfast items**, like **\"White Pearl Onions\"** and **\"Organic Clementines.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf15e27-9daa-45e0-8a08-67a18be4377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21174b0d-f8ac-4af0-92cb-a1717bf1ce55",
   "metadata": {},
   "source": [
    "## Create a Subset for Breakfast Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200ad20-295c-4a4a-854f-1909080046e2",
   "metadata": {},
   "source": [
    "6. The sales team in your client’s organization wants to know more about breakfast item sales. Create a subset containing only the required information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9a9299d-acb7-4e87-af0f-f43603bb03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product_id                    product_name  aisle_id  department_id  \\\n",
      "30          31              White Pearl Onions       123              4   \n",
      "42          43             Organic Clementines       123              4   \n",
      "44          45               European Cucumber        83              4   \n",
      "65          66       European Style Spring Mix       123              4   \n",
      "88          89  Yogurt Fruit Dip Sliced Apples       123              4   \n",
      "\n",
      "    prices  \n",
      "30     7.5  \n",
      "42    11.5  \n",
      "44    14.3  \n",
      "65    11.7  \n",
      "88    12.6  \n"
     ]
    }
   ],
   "source": [
    "# Subset for breakfast items (department_id = 4)\n",
    "df_breakfast = df_prods[df_prods['department_id'] == 4]\n",
    "\n",
    "# Verify the subset\n",
    "print(df_breakfast.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6674c2-a406-45ff-9b67-9fd522d13d48",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I created a subset for breakfast items **(department_id = 4)** and saved it as `df_breakfast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eff656-93e9-410f-aa2f-ed26079e969c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b935c6e6-e439-4b8e-aaee-b4418e9f042e",
   "metadata": {},
   "source": [
    "## Create a Subset for Dinner Party Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27238d-3cd2-441c-a5df-82503495d559",
   "metadata": {},
   "source": [
    "7. The client wants to see details about products that customers might use to throw dinner parties. The task is to find all observations from the entire dataframe that include items from the following departments: alcohol, deli, beverages, and meat/seafood. I will need to present this subset to my client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2ec2d897-7549-4588-abf6-13bc43de1b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product_id                                    product_name  aisle_id  \\\n",
      "2            3            Robust Golden Unsweetened Oolong Tea        94   \n",
      "6            7                  Pure Coconut Water With Orange        98   \n",
      "9           10  Sparkling Orange Juice & Prickly Pear Beverage       115   \n",
      "10          11                               Peach Mango Juice        31   \n",
      "16          17                               Rendered Duck Fat        35   \n",
      "\n",
      "    department_id  prices  \n",
      "2               7     4.5  \n",
      "6               7     4.4  \n",
      "9               7     8.4  \n",
      "10              7     2.8  \n",
      "16             12    17.1  \n"
     ]
    }
   ],
   "source": [
    "# Subset for dinner party items (departments: alcohol, deli, beverages, meat/seafood)\n",
    "dinner_party_departments = [5, 20, 7, 12]  # Department IDs for alcohol, deli, beverages, and meat/seafood\n",
    "df_dinner_party = df_prods[df_prods['department_id'].isin(dinner_party_departments)]\n",
    "\n",
    "# Verify the subset\n",
    "print(df_dinner_party.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d4eb9-4cb8-4e6c-a44c-864576ae1b49",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I created a subset for dinner party items using department IDs 5 (alcohol), 20 (deli), 7 (beverages), and 12 (meat/seafood). This subset includes **7,650 rows**, with items like **\"Rendered Duck Fat\"** and **\"Sparkling Orange Juice.\"** These departments cover key categories for dinner parties: alcohol, deli, beverages, and meat/seafood. I saved the subset as `df_dinner_party`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b540f60-54ed-4426-95f5-9af08b09776b",
   "metadata": {},
   "source": [
    "#### Additional Context \n",
    "These department IDs (5 for alcohol, 20 for deli, 7 for beverages, and 12 for meat/seafood) come from the data dictionary included in the Instacart dataset. I used this information to ensure the subset accurately represents products relevant to dinner party preparations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecde7a4-fb61-4edc-a394-f86c8ba31abf",
   "metadata": {},
   "source": [
    "## Count the Rows in the Last Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a8e61-bc45-4e1f-b870-5809d7418dfc",
   "metadata": {},
   "source": [
    "8. It’s important that you keep track of the total counts in your dataframes. How many rows does the last dataframe you created have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6560841e-bf74-4d10-a319-83978c029713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df_dinner_party dataframe contains 7650 rows.\n"
     ]
    }
   ],
   "source": [
    "# Count the rows in the df_dinner_party dataframe\n",
    "row_count = df_dinner_party.shape[0]\n",
    "\n",
    "# Display the row count\n",
    "print(f\"The df_dinner_party dataframe contains {row_count} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02902769-4b5e-412e-859d-0c240e3a1995",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "After running the code I checked the `df_dinner_party` dataframe and found that it contains **7,650 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadeab9-0f80-40d8-be89-f9d575b13670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9adebc4f-efce-4e20-ab4b-dbd33d65b64d",
   "metadata": {},
   "source": [
    "## Extract Information About a Specific User"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf4c7a-d792-46c7-aace-a548bef173cc",
   "metadata": {},
   "source": [
    "9. Someone from the data engineers team at Instacart thinks they’ve spotted something strange about the customer with a \"user_id\" of 1. Extract all the information you can about this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f25f47e9-9baf-4122-aff9-fd6c4f3a6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    order_id  user_id eval_set  order_number  order_day_of_week  \\\n",
      "0    2539329        1    prior             1                  2   \n",
      "1    2398795        1    prior             2                  3   \n",
      "2     473747        1    prior             3                  3   \n",
      "3    2254736        1    prior             4                  4   \n",
      "4     431534        1    prior             5                  4   \n",
      "5    3367565        1    prior             6                  2   \n",
      "6     550135        1    prior             7                  1   \n",
      "7    3108588        1    prior             8                  1   \n",
      "8    2295261        1    prior             9                  1   \n",
      "9    2550362        1    prior            10                  4   \n",
      "10   1187899        1    train            11                  4   \n",
      "\n",
      "    order_hour_of_day  days_since_prior_order  \n",
      "0                   8                     NaN  \n",
      "1                   7                    15.0  \n",
      "2                  12                    21.0  \n",
      "3                   7                    29.0  \n",
      "4                  15                    28.0  \n",
      "5                   7                    19.0  \n",
      "6                   9                    20.0  \n",
      "7                  14                    14.0  \n",
      "8                  16                     0.0  \n",
      "9                   8                    30.0  \n",
      "10                  8                    14.0  \n"
     ]
    }
   ],
   "source": [
    "# Extract information about user_id 1\n",
    "user_1_data = df_ords[df_ords['user_id'] == 1]\n",
    "\n",
    "# Display the data\n",
    "print(user_1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9024e-2d7e-4b47-8164-8cdfe5b16107",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I extracted all the data for the `user with user_id = 1`. I found that this user has **11 orders** in total. Most of their orders are from the prior dataset, and one is from the train dataset. Their orders span different days of the week and hours, with varying gaps between orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa224431-a8f6-4bdc-9685-24445ed2261a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed74404e-32c4-4e20-b6ac-b9bb107599fa",
   "metadata": {},
   "source": [
    "## Analyze User Behavior for user_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a41f4-ed81-44e4-8f95-482398e89122",
   "metadata": {},
   "source": [
    "10. You also need to provide some details about this user’s behavior. What basic stats can you provide based on the information you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7177fcbb-162c-46c1-b742-f104a01d97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           order_id  user_id  order_number  order_day_of_week  \\\n",
      "count  1.100000e+01     11.0     11.000000          11.000000   \n",
      "mean   1.923450e+06      1.0      6.000000           2.636364   \n",
      "std    1.071950e+06      0.0      3.316625           1.286291   \n",
      "min    4.315340e+05      1.0      1.000000           1.000000   \n",
      "25%    8.690170e+05      1.0      3.500000           1.500000   \n",
      "50%    2.295261e+06      1.0      6.000000           3.000000   \n",
      "75%    2.544846e+06      1.0      8.500000           4.000000   \n",
      "max    3.367565e+06      1.0     11.000000           4.000000   \n",
      "\n",
      "       order_hour_of_day  days_since_prior_order  \n",
      "count          11.000000               10.000000  \n",
      "mean           10.090909               19.000000  \n",
      "std             3.477198                9.030811  \n",
      "min             7.000000                0.000000  \n",
      "25%             7.500000               14.250000  \n",
      "50%             8.000000               19.500000  \n",
      "75%            13.000000               26.250000  \n",
      "max            16.000000               30.000000  \n"
     ]
    }
   ],
   "source": [
    "# Calculate basic stats for user_id 1\n",
    "user_1_stats = user_1_data.describe()\n",
    "\n",
    "# Display the stats\n",
    "print(user_1_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe4ae7-ab62-420b-9295-06617696bf8e",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "I analyzed the behavior of `user_id = 1` and found that they placed **11 orders** in total. Their orders are mostly placed around **10 AM** on average, and the average gap between their orders is about **19 days.** The minimum time between their orders is **14 days,** while the maximum is **30 days.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8e29c-d94b-4c58-89c7-29f2b2f1cbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ed8dbce-b2df-4a81-b700-34ba411a32fa",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "This notebook contains an analysis of the Instacart dataset. Below are the key findings:\n",
    "\n",
    "1. **Converted Identifier Variable to String:**  \n",
    "       I changed the `order_id` column to a string so it’s treated as an identifier instead of a number.\n",
    "    \n",
    "2. **Renamed Unintuitive Column:**  \n",
    "       I renamed the `order_dow` column to `order_day_of_week` to make it more clear and easier to understand.\n",
    "    \n",
    "3. **Identified Busiest Hour for Orders:**  \n",
    "       The busiest hour for placing orders is **10 AM**, with **283,728 orders** during that time.\n",
    "    \n",
    "4. **Determined Meaning of Department ID 4:**  \n",
    "       I found that department ID 4 corresponds to **breakfast items**, including things like **\"White Pearl Onions\"** and **\"Organic Clementines.\"**\n",
    "\n",
    "5. **Created a Subset for Breakfast Items:**  \n",
    "       I created a subset of the data for **breakfast items (department_id = 4)** and saved it as `df_breakfast`.\n",
    "\n",
    "6. **Created a Subset for Dinner Party Items:**\n",
    "   - I made a subset for dinner party items using **department IDs 5 (alcohol), 20 (deli), 7 (beverages), and 12 (meat/seafood)**.  \n",
    "   - This subset includes **7,650 rows**, with items like **\"Rendered Duck Fat\"** and **\"Sparkling Orange Juice.\"**  \n",
    "   - I saved this subset as `df_dinner_party`.\n",
    "<div style=\"margin-bottom: 20px;\"></div>\n",
    "\n",
    "7. **Counted Rows in the Last Dataframe:**  \n",
    "       I verified that the `df_dinner_party` dataframe has **7,650 rows**.\n",
    "\n",
    "8. **Extracted Information About a Specific User:**  \n",
    "       I pulled all orders placed by **user_id = 1**, which included **11 total orders** across different days and times.\n",
    "\n",
    "9. **Analyzed User Behavior for user_id = 1:**  \n",
    "       After running some basic stats, I found this user places most orders between **10 AM and 11 AM**, and there’s an average of **19 days between their orders**.\n",
    "\n",
    "---\n",
    "\n",
    "This summary brings together all the key insights from my analysis and serves as a handy reference for what I accomplished in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84711cd-4215-4ba7-b223-2f9651341573",
   "metadata": {},
   "source": [
    "## Export `df_ords` as `orders_wrangled.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f4cb95c1-edd6-443a-94ca-656c0b3a5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the \"Prepared Data\" folder\n",
    "prepared_data_path = r'C:\\Users\\Ripple\\Desktop\\YVC\\Data Analytics (CF)\\Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Prepared Data'\n",
    "\n",
    "# Export df_ords as orders_wrangled.csv\n",
    "df_ords.to_csv(os.path.join(prepared_data_path, 'orders_wrangled.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7387b-c086-42fc-a630-1741f4e63b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23af4ff5-06b7-4be1-9678-07f38940934e",
   "metadata": {},
   "source": [
    "## Export `df_dep_t_new` as `departments_wrangled.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba4263-5fe1-4717-84ad-797fa8d753ed",
   "metadata": {},
   "source": [
    "### Update the File Path and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "681c7c9a-f40e-4a0f-9451-1e87cd24daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  department_id       1      2       3        4        5              6  \\\n",
      "0    department  frozen  other  bakery  produce  alcohol  international   \n",
      "\n",
      "           7     8                9  ...            12      13         14  \\\n",
      "0  beverages  pets  dry goods pasta  ...  meat seafood  pantry  breakfast   \n",
      "\n",
      "             15          16         17      18      19    20       21  \n",
      "0  canned goods  dairy eggs  household  babies  snacks  deli  missing  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Path to 'departments.csv'\n",
    "departments_path = os.path.join(path, '02 Data', 'Original Data', 'departments.csv')\n",
    "\n",
    "# Load the file into a DataFrame\n",
    "df_dep = pd.read_csv(departments_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to confirm it loaded successfully\n",
    "print(df_dep.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616945af-e479-496e-9e95-6942de7b3053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "240117e3-019c-4969-93c9-d11f0a6c1bc1",
   "metadata": {},
   "source": [
    "### Transpose the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "30c89f1b-64b2-4c84-97dc-f5da7b6c3011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0\n",
      "department_id  department\n",
      "1                  frozen\n",
      "2                   other\n",
      "3                  bakery\n",
      "4                 produce\n"
     ]
    }
   ],
   "source": [
    "# Transpose the DataFrame\n",
    "df_dep_t = df_dep.T\n",
    "\n",
    "# Display the transposed DataFrame\n",
    "print(df_dep_t.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d4550-49f7-4bea-bf71-6925dc920427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef742c4f-5d52-48fc-8912-be5d4cfdd032",
   "metadata": {},
   "source": [
    "### Update the Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2a54e89c-0cb7-4f12-9cfb-9d386878cf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department_id department\n",
      "1                 frozen\n",
      "2                  other\n",
      "3                 bakery\n",
      "4                produce\n",
      "5                alcohol\n"
     ]
    }
   ],
   "source": [
    "# Extract the first row as a new header\n",
    "new_header = df_dep_t.iloc[0]  # First row as header\n",
    "\n",
    "# Create a new DataFrame without the first row\n",
    "df_dep_t_new = df_dep_t[1:]  # Remove the first row\n",
    "\n",
    "# Assign the new headers to the DataFrame\n",
    "df_dep_t_new.columns = new_header\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_dep_t_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53f79d-f9c2-4949-b226-55bac1716703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34cc5560-2e78-4ee9-a445-a83a8dbf1c05",
   "metadata": {},
   "source": [
    "### Export the Updated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7680f319-7016-4d0f-a8e9-ed4c80400334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export df_dep_t_new as departments_wrangled.csv\n",
    "df_dep_t_new.to_csv(os.path.join(prepared_data_path, 'departments_wrangled.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebd8d8-3b96-44b6-9114-bc98f8579dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
