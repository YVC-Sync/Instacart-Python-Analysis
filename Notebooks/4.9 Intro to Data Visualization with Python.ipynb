{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edab6237-edd8-4020-9818-a556ded079ce",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this task, I will incorporate customer data into my Instacart dataset and perform exploratory data analysis using visualizations. \n",
    "The goal is to uncover insights that can help Instacart stakeholders make data-driven marketing and business decisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02a7ca-ed0c-4e8f-86de-054bc65bb525",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "1. Introduction\n",
    "2. Importing Libraries and Loading Data\n",
    "3. Data Quality and Cleaning\n",
    "    - Handling Missing Values\n",
    "    - Handling Duplicates\n",
    "4. Checking and Fixing Data Types\n",
    "5. Merging Customer Data with Instacart Data\n",
    "    - Checking Key Columns Before Merging\n",
    "    - Merging the Datasets\n",
    "6. Exporting the Merged Dataset\n",
    "7. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d1f40-2fb8-4ed7-b1ae-48bc5960be88",
   "metadata": {},
   "source": [
    "### **Key Objectives:**\n",
    "- Merge customer data with the Instacart dataset.\n",
    "- Perform data cleaning and consistency checks.\n",
    "- Generate **four types of visualizations**: histograms, bar charts, scatterplots, and line charts.\n",
    "- Analyze relationships between customer demographics and purchasing behavior.\n",
    "- Save visualizations for final report documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b79f7-eaa5-4dc2-927e-de8062b5b5de",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. **Importing Libraries and Loading Data**\n",
    "   - Import necessary libraries  \n",
    "   - Load customer data and Instacart data  \n",
    "   - Initial data exploration  \n",
    "\n",
    "3. **Data Cleaning and Wrangling**  \n",
    "   - Checking for missing values and duplicates  \n",
    "   - Renaming columns and correcting data types  \n",
    "   - Merging customer data with Instacart dataset\n",
    "\n",
    "4. **Exploratory Data Analysis & Visualizations**  \n",
    "   - Creating a histogram for order times  \n",
    "   - Creating a bar chart for customer loyalty distribution  \n",
    "   - Creating a line chart for spending behavior by hour  \n",
    "   - Creating a scatterplot for income vs. age  \n",
    "\n",
    "5. **Insights & Conclusions**  \n",
    "   - Summary of findings  \n",
    "   - Key takeaways for Instacart stakeholders  \n",
    "\n",
    "6. **Exporting Visualizations & Saving Notebook**  \n",
    "   - Save plots as PNG files  \n",
    "   - Export cleaned dataset for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5545270-2aab-48d8-9f69-29623fe125e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35885ba9-4205-4133-8a66-84eedcae288c",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries and Loading Data\n",
    "Before I can start working with the data, I need to set up my environment by importing the libraries I'll be using. These will help me handle data, perform calculations, and create visualizations later on.  \n",
    "\n",
    "### **Libraries I'll Be Using:**  \n",
    "- **pandas** ‚Üí for handling and manipulating data  \n",
    "- **numpy** ‚Üí for numerical operations  \n",
    "- **matplotlib & seaborn** ‚Üí for data visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dda57c87-1ab9-4f6f-b356-b9816a3af0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make sure all columns are visible when displaying data\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02560c8b-8a25-47cd-bb77-019a4f8d9cc2",
   "metadata": {},
   "source": [
    "### Loading the Customer Data  \n",
    "\n",
    "Now that the libraries are ready, it's time to load the customer dataset. This data contains information about Instacart users, which I'll be merging with my existing Instacart order data later.  \n",
    "\n",
    "First, I'll load the file and check the first few rows to make sure everything looks good.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efdae037-8760-4e00-b034-91d45cec0b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Surnam</th>\n",
       "      <th>Gender</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>n_dependants</th>\n",
       "      <th>fam_status</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26711</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>Esquivel</td>\n",
       "      <td>Female</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>48</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>165665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33890</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>Hart</td>\n",
       "      <td>Female</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>36</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>59285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65803</td>\n",
       "      <td>Kenneth</td>\n",
       "      <td>Farley</td>\n",
       "      <td>Male</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>35</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>married</td>\n",
       "      <td>99568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125935</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Hicks</td>\n",
       "      <td>Female</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>40</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>42049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130797</td>\n",
       "      <td>Ann</td>\n",
       "      <td>Gilmore</td>\n",
       "      <td>Female</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>26</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>40374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id First Name    Surnam  Gender       STATE  Age date_joined  \\\n",
       "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
       "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
       "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
       "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
       "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
       "\n",
       "   n_dependants fam_status  income  \n",
       "0             3    married  165665  \n",
       "1             0     single   59285  \n",
       "2             2    married   99568  \n",
       "3             0     single   42049  \n",
       "4             1    married   40374  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the file path to the customer dataset\n",
    "file_path = r\"D:\\YVC\\Data Analytics (CF)\\üêç Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Original Data\\customers.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df_customers = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to confirm the data loaded correctly\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b71aa-6c3f-4f4e-b395-6c70fe955d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58a7c851-9c1f-4dc6-b4ae-8bd16958602e",
   "metadata": {},
   "source": [
    "## 2. Data Quality and Cleaning  \n",
    "\n",
    "Before I merge the customer dataset with my Instacart data, I need to make sure everything is clean and ready to go. That means checking for:  \n",
    "- **Missing values** ‚Üí to see if any important data is missing.  \n",
    "- **Duplicates** ‚Üí to avoid errors from repeated data.  \n",
    "- **Data types** ‚Üí to make sure everything is formatted correctly.  \n",
    "\n",
    "Once I know what (if anything) needs fixing, I‚Äôll clean up the dataset before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e19ced3b-0993-4e8c-86ad-0d24caff7c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             0\n",
       "First Name      11259\n",
       "Surnam              0\n",
       "Gender              0\n",
       "STATE               0\n",
       "Age                 0\n",
       "date_joined         0\n",
       "n_dependants        0\n",
       "fam_status          0\n",
       "income              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the customer dataset\n",
    "df_customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220fb52c-e099-4695-abad-6bbb584af96c",
   "metadata": {},
   "source": [
    "### Handling Missing Values  \n",
    "\n",
    "Now that I‚Äôve checked for missing values, I need to decide what to do with them. If any important columns have missing values, I might need to fill them in or drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "650cbd72-d12a-45d9-9799-489a482056a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate rows in the customer dataset\n",
    "df_customers.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ba471-0008-46fc-991a-02a783ef01b7",
   "metadata": {},
   "source": [
    "### Handling Duplicates  \n",
    "\n",
    "If I find any duplicate rows, I‚Äôll remove them to make sure my dataset is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1d2cc3a-bd4a-4f23-b78e-01b778ed66ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       206209 non-null  int64 \n",
      " 1   First Name    194950 non-null  object\n",
      " 2   Surnam        206209 non-null  object\n",
      " 3   Gender        206209 non-null  object\n",
      " 4   STATE         206209 non-null  object\n",
      " 5   Age           206209 non-null  int64 \n",
      " 6   date_joined   206209 non-null  object\n",
      " 7   n_dependants  206209 non-null  int64 \n",
      " 8   fam_status    206209 non-null  object\n",
      " 9   income        206209 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types of each column\n",
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026f67e-e9ce-4b36-a014-c551fd03303a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e96855-2018-448f-905d-ea4d4f3681ac",
   "metadata": {},
   "source": [
    "Since the \"First Name\" column has **11,259 missing values**, I need to decide whether to drop it or fill in the blanks.  \n",
    "\n",
    "- **Dropping the column** makes sense if it‚Äôs not useful for my analysis.  \n",
    "- **Filling missing values** with something like `\"Unknown\"` could help if I need to keep it.  \n",
    "\n",
    "Since names aren‚Äôt critical for my analysis, I‚Äôm going to drop the column to keep my dataset clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90725e88-e19b-471b-9dc6-8777ffccd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'First Name' column since it's not needed\n",
    "df_customers.drop(columns=['First Name'], inplace=True)\n",
    "\n",
    "# Verify that the column was removed\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f2a47-0b6b-4a9b-9b75-33be09d4acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ab5027d-6cb8-4680-afb1-a04d09de0846",
   "metadata": {},
   "source": [
    "## 4. Checking and Fixing Data Types  \n",
    "\n",
    "Now that my dataset is cleaned up, I need to make sure all the columns have the correct data types. This is important because:  \n",
    "- If a numeric column is stored as text, calculations won‚Äôt work properly.  \n",
    "- If a date column is stored as text, I can‚Äôt use date-based functions.  \n",
    "- If my key column (**user_id**) isn‚Äôt a string, merging with other datasets could cause errors.  \n",
    "\n",
    "I‚Äôll check the data types now and fix any issues before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "592dee60-7619-4f28-8cf6-08c6cd501cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id          int64\n",
       "First Name      object\n",
       "Surnam          object\n",
       "Gender          object\n",
       "STATE           object\n",
       "Age              int64\n",
       "date_joined     object\n",
       "n_dependants     int64\n",
       "fam_status      object\n",
       "income           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types of each column\n",
    "df_customers.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a195d-83a8-4f00-a353-f998e3872495",
   "metadata": {},
   "source": [
    "### Fixing Incorrect Data Types  \n",
    "\n",
    "Now that I‚Äôve checked the data types, I‚Äôll fix any issues to make sure my dataset is in the best shape before merging.  \n",
    "- **user_id** should be a string, not a number.  \n",
    "- **date_joined** should be in a proper date format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a35281a-7a22-4a3f-9e9b-4bb75d0eeae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                 object\n",
       "First Name              object\n",
       "Surnam                  object\n",
       "Gender                  object\n",
       "STATE                   object\n",
       "Age                      int64\n",
       "date_joined     datetime64[ns]\n",
       "n_dependants             int64\n",
       "fam_status              object\n",
       "income                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'user_id' to a string\n",
    "df_customers['user_id'] = df_customers['user_id'].astype(str)\n",
    "\n",
    "# Convert 'date_joined' to a datetime format\n",
    "df_customers['date_joined'] = pd.to_datetime(df_customers['date_joined'])\n",
    "\n",
    "# Verify the changes\n",
    "df_customers.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f260e-3abd-4264-b46d-12de3a8da988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e890f13e-62e5-41d3-b03c-6e2b40c328c9",
   "metadata": {},
   "source": [
    "## 5. Merging Customer Data with Instacart Data  \n",
    "\n",
    "Now that my customer data is cleaned and formatted correctly, I‚Äôm going to merge it with my **Instacart orders dataset**.  \n",
    "\n",
    "### **Why This Merge is Important:**  \n",
    "- It allows me to connect **customer details** with their **order history**.  \n",
    "- I can analyze **spending habits**, **loyalty trends**, and **demographics**.  \n",
    "\n",
    "Before merging, I need to make sure the key column (**user_id**) is the same in both datasets to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e166f9c-dab1-4465-b6c0-0a7738b85d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id eval_set  order_number  orders_day_of_week  \\\n",
       "0   2539329        1    prior             1                   2   \n",
       "1   2398795        1    prior             2                   3   \n",
       "2    473747        1    prior             3                   3   \n",
       "3   2254736        1    prior             4                   4   \n",
       "4    431534        1    prior             5                   4   \n",
       "\n",
       "   order_hour_of_day  days_since_prior_order  \n",
       "0                  8                     NaN  \n",
       "1                  7                    15.0  \n",
       "2                 12                    21.0  \n",
       "3                  7                    29.0  \n",
       "4                 15                    28.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define file path for the Instacart orders dataset\n",
    "orders_path = r\"D:\\YVC\\Data Analytics (CF)\\üêç Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\cleaned_orders.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df_orders = pd.read_csv(orders_path)\n",
    "\n",
    "# Display first few rows to confirm it loaded correctly\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded36c9-783b-4117-a839-c5a91a348045",
   "metadata": {},
   "source": [
    "### Checking Key Columns Before Merging  \n",
    "\n",
    "To make sure the merge works properly, I need to check that **user_id** is formatted correctly in both datasets.  \n",
    "\n",
    "- **Both columns should be the same data type (string).**  \n",
    "- If not, I‚Äôll convert them to match.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe06a555-9a3c-4c17-8b2e-20e4dca69ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object object\n"
     ]
    }
   ],
   "source": [
    "# Ensure user_id is a string in both datasets\n",
    "df_orders['user_id'] = df_orders['user_id'].astype(str)\n",
    "df_customers['user_id'] = df_customers['user_id'].astype(str)\n",
    "\n",
    "# Verify the data types again\n",
    "print(df_orders.dtypes['user_id'], df_customers.dtypes['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55667af8-5346-43d8-9004-962f9a2fe20b",
   "metadata": {},
   "source": [
    "### Merging the Datasets  \n",
    "\n",
    "Now that everything is formatted correctly, I can merge the datasets using **user_id** as the key.  \n",
    "- I‚Äôll use a **left join** so that all existing Instacart orders stay in the dataset, even if some users don‚Äôt have matching customer details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc51c898-96eb-4467-ba23-995966c9f028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Surnam</th>\n",
       "      <th>Gender</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>n_dependants</th>\n",
       "      <th>fam_status</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id user_id eval_set  order_number  orders_day_of_week  \\\n",
       "0   2539329       1    prior             1                   2   \n",
       "1   2398795       1    prior             2                   3   \n",
       "2    473747       1    prior             3                   3   \n",
       "3   2254736       1    prior             4                   4   \n",
       "4    431534       1    prior             5                   4   \n",
       "\n",
       "   order_hour_of_day  days_since_prior_order First Name  Surnam  Gender  \\\n",
       "0                  8                     NaN      Linda  Nguyen  Female   \n",
       "1                  7                    15.0      Linda  Nguyen  Female   \n",
       "2                 12                    21.0      Linda  Nguyen  Female   \n",
       "3                  7                    29.0      Linda  Nguyen  Female   \n",
       "4                 15                    28.0      Linda  Nguyen  Female   \n",
       "\n",
       "     STATE  Age date_joined  n_dependants fam_status  income  \n",
       "0  Alabama   31  2019-02-17             3    married   40423  \n",
       "1  Alabama   31  2019-02-17             3    married   40423  \n",
       "2  Alabama   31  2019-02-17             3    married   40423  \n",
       "3  Alabama   31  2019-02-17             3    married   40423  \n",
       "4  Alabama   31  2019-02-17             3    married   40423  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge orders with customer data\n",
    "df_merged = df_orders.merge(df_customers, on='user_id', how='left')\n",
    "\n",
    "# Display first few rows of the merged dataset\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259571fa-4ba9-444c-9002-4251750c3a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff701f80-764d-442d-bf31-50e68a820fce",
   "metadata": {},
   "source": [
    "## 6. Exporting the Merged Dataset  \n",
    "\n",
    "Now that my dataset is fully cleaned and merged, I‚Äôll save it so I can use it later for data visualization.  \n",
    "\n",
    "### **Why Exporting is Important?**  \n",
    "- It keeps my work **organized** and **reusable**.  \n",
    "- I won‚Äôt have to redo the merge every time I reopen my notebook.  \n",
    "- I can quickly load this dataset in **Part 2** to create visualizations.  \n",
    "\n",
    "I‚Äôll save it in **pickle format (.pkl)** since it loads faster than a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9cef77c0-ef3b-4f5e-a6f9-6ab19a6aac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully saved as a pickle file!\n"
     ]
    }
   ],
   "source": [
    "# Define file path for export\n",
    "export_path = r\"D:\\YVC\\Data Analytics (CF)\\üêç Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\merged_orders_customers.pkl\"\n",
    "\n",
    "# Save the merged dataset as a pickle file\n",
    "df_merged.to_pickle(export_path)\n",
    "\n",
    "# Confirm the export\n",
    "print(\"Dataset successfully saved as a pickle file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fbc185-eadb-46f0-8a8a-ab52b3cc2ff2",
   "metadata": {},
   "source": [
    "### Next Steps  \n",
    "\n",
    "Now that my dataset is saved, I can move on to **Part 2**, where I‚Äôll create visualizations to analyze trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf68bd-5a5e-4cd9-953f-ed784d75c1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
