{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c330f74-70fa-4326-86c2-482815423d0f",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "1. Data Consistency Checks\n",
    "2. Step 1: Import Libraries\n",
    "3. Step 2: Import Datasets\n",
    "4. Step 3: Descriptive Statistics\n",
    "5. Step 4: Check for Mixed-Type Columns\n",
    "6. Step 5: Check for Missing Values\n",
    "7. Step 6: Check for Duplicates\n",
    "8. Step 7: Save Cleaned Data\n",
    "9. Verify Saved Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681d744-8fb0-4ec9-a3ae-4b72bf76049b",
   "metadata": {},
   "source": [
    "# Data Consistency Checks\n",
    "This notebook is all about performing data consistency checks for the Instacart Basket Analysis project. I’ll be cleaning the data, checking for missing values, duplicates, and mixed data types to make sure everything is ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f899d78-7ebe-4da7-b3f2-da2b0130eb1e",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "First, I’ll load the libraries I’ll need for working with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5172a1-f7a3-4419-ae5d-f01128ec8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c311280-ae51-4c8d-b229-8b9324369b04",
   "metadata": {},
   "source": [
    "## Step 2: Import Datasets\n",
    "Time to bring in the data I’ll be working with! These include the `products`, `orders`, and a few other files. I’ll load them into pandas dataframes so I can start cleaning them up and checking for any consistency issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65f13e18-ddc7-49bf-82b7-e1c3517d3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "df_prods = pd.read_csv('../02 Data/Original Data/products.csv')  # Products dataset\n",
    "df_departments = pd.read_csv('../02 Data/Original Data/departments.csv')  # Departments dataset\n",
    "df_orders = pd.read_csv('../02 Data/Original Data/orders.csv')  # Orders dataset\n",
    "\n",
    "# Prepared data\n",
    "df_cleaned_prods = pd.read_csv('../02 Data/Prepared Data/cleaned_products.csv')  # Cleaned products\n",
    "df_orders_wrangled = pd.read_csv('../02 Data/Prepared Data/orders_wrangled.csv')  # Wrangled orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6600c316-f977-402d-a4d6-381563c3bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products Data:\n",
      "   product_id                                       product_name  aisle_id  \\\n",
      "0           1                         Chocolate Sandwich Cookies        61   \n",
      "1           2                                   All-Seasons Salt       104   \n",
      "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
      "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
      "4           5                          Green Chile Anytime Sauce         5   \n",
      "\n",
      "   department_id  prices  \n",
      "0             19     5.8  \n",
      "1             13     9.3  \n",
      "2              7     4.5  \n",
      "3              1    10.5  \n",
      "4             13     4.3   \n",
      "\n",
      "Departments Data:\n",
      "  department_id       1      2       3        4        5              6  \\\n",
      "0    department  frozen  other  bakery  produce  alcohol  international   \n",
      "\n",
      "           7     8                9  ...            12      13         14  \\\n",
      "0  beverages  pets  dry goods pasta  ...  meat seafood  pantry  breakfast   \n",
      "\n",
      "             15          16         17      18      19    20       21  \n",
      "0  canned goods  dairy eggs  household  babies  snacks  deli  missing  \n",
      "\n",
      "[1 rows x 22 columns] \n",
      "\n",
      "Orders Data:\n",
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2398795        1    prior             2          3                  7   \n",
      "2    473747        1    prior             3          3                 12   \n",
      "3   2254736        1    prior             4          4                  7   \n",
      "4    431534        1    prior             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  \n",
      "0                     NaN  \n",
      "1                    15.0  \n",
      "2                    21.0  \n",
      "3                    29.0  \n",
      "4                    28.0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview datasets\n",
    "print(\"Products Data:\")\n",
    "print(df_prods.head(), \"\\n\")\n",
    "\n",
    "print(\"Departments Data:\")\n",
    "print(df_departments.head(), \"\\n\")\n",
    "\n",
    "print(\"Orders Data:\")\n",
    "print(df_orders.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1992394-6509-4aae-aaed-34f5072f6273",
   "metadata": {},
   "source": [
    "## Step 3: Descriptive Statistics\n",
    "I'll start by running descriptive statistics on the datasets to get an overview of the data and check for anything unusual. This will help identify potential outliers or inconsistencies in the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e37b816-380d-400e-a243-1cbd10dbe8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Orders Data:\n",
      "           order_id       user_id  order_number     order_dow  \\\n",
      "count  3.421083e+06  3.421083e+06  3.421083e+06  3.421083e+06   \n",
      "mean   1.710542e+06  1.029782e+05  1.715486e+01  2.776219e+00   \n",
      "std    9.875817e+05  5.953372e+04  1.773316e+01  2.046829e+00   \n",
      "min    1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
      "25%    8.552715e+05  5.139400e+04  5.000000e+00  1.000000e+00   \n",
      "50%    1.710542e+06  1.026890e+05  1.100000e+01  3.000000e+00   \n",
      "75%    2.565812e+06  1.543850e+05  2.300000e+01  5.000000e+00   \n",
      "max    3.421083e+06  2.062090e+05  1.000000e+02  6.000000e+00   \n",
      "\n",
      "       order_hour_of_day  days_since_prior_order  \n",
      "count       3.421083e+06            3.214874e+06  \n",
      "mean        1.345202e+01            1.111484e+01  \n",
      "std         4.226088e+00            9.206737e+00  \n",
      "min         0.000000e+00            0.000000e+00  \n",
      "25%         1.000000e+01            4.000000e+00  \n",
      "50%         1.300000e+01            7.000000e+00  \n",
      "75%         1.600000e+01            1.500000e+01  \n",
      "max         2.300000e+01            3.000000e+01   \n",
      "\n",
      "Descriptive Statistics for Products Data:\n",
      "         product_id      aisle_id  department_id        prices\n",
      "count  49693.000000  49693.000000   49693.000000  49693.000000\n",
      "mean   24844.345139     67.770249      11.728433      9.994136\n",
      "std    14343.717401     38.316774       5.850282    453.519686\n",
      "min        1.000000      1.000000       1.000000      1.000000\n",
      "25%    12423.000000     35.000000       7.000000      4.100000\n",
      "50%    24845.000000     69.000000      13.000000      7.100000\n",
      "75%    37265.000000    100.000000      17.000000     11.200000\n",
      "max    49688.000000    134.000000      21.000000  99999.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for orders\n",
    "print(\"Descriptive Statistics for Orders Data:\")\n",
    "print(df_orders.describe(), \"\\n\")\n",
    "\n",
    "# Descriptive statistics for products\n",
    "print(\"Descriptive Statistics for Products Data:\")\n",
    "print(df_prods.describe(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a9780-3d8d-49b8-b207-f183a2ee3ba2",
   "metadata": {},
   "source": [
    "## Step 4: Check for Mixed-Type Columns\n",
    "Next, I'll check if any of the columns have mixed data types, as this can cause problems during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4bfa091-1720-4dad-a64b-d43d086de3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for mixed-type columns\n",
    "for col in df_orders.columns:\n",
    "    mixed_types = (df_orders[col].apply(type).nunique() > 1)\n",
    "    if mixed_types:\n",
    "        print(f\"Column {col} contains mixed data types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dde476-0014-4049-854f-af974e4ff01b",
   "metadata": {},
   "source": [
    "## Step 5: Check for Missing Values\n",
    "Check for missing values in the data to ensure there aren’t any gaps that could cause problems during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ce2f6a7-dadf-4ddd-863b-2cf495f68b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Orders Data:\n",
      "order_id                       0\n",
      "user_id                        0\n",
      "eval_set                       0\n",
      "order_number                   0\n",
      "order_dow                      0\n",
      "order_hour_of_day              0\n",
      "days_since_prior_order    206209\n",
      "dtype: int64 \n",
      "\n",
      "Missing Values in Products Data:\n",
      "product_id        0\n",
      "product_name     16\n",
      "aisle_id          0\n",
      "department_id     0\n",
      "prices            0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"Missing Values in Orders Data:\")\n",
    "print(df_orders.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Missing Values in Products Data:\")\n",
    "print(df_prods.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41044cdb-f287-411a-b77b-ad269d3a1316",
   "metadata": {},
   "source": [
    "## Step 6: Check for Duplicates\n",
    "I'll check if there are any duplicate rows in the data that need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e89a706-ad8c-4e4e-b1dc-348b4a653a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows in Orders Data:\n",
      "0 \n",
      "\n",
      "Duplicate Rows in Products Data:\n",
      "5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "print(\"Duplicate Rows in Orders Data:\")\n",
    "print(df_orders.duplicated().sum(), \"\\n\")\n",
    "\n",
    "print(\"Duplicate Rows in Products Data:\")\n",
    "print(df_prods.duplicated().sum(), \"\\n\")\n",
    "\n",
    "# Removing duplicates\n",
    "df_orders = df_orders.drop_duplicates()\n",
    "df_prods = df_prods.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9930f86-fdc7-49db-bfe9-0e1e20f4deaf",
   "metadata": {},
   "source": [
    "## Step 7: Save Cleaned Data\n",
    "Now that the data has been checked and cleaned, I’ll export the cleaned dataframes to my \"Prepared Data\" folder for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f338756-529e-46eb-8eeb-3bbbdca70fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df_orders.to_csv('../02 Data/Prepared Data/cleaned_orders.csv', index=False)\n",
    "df_prods.to_csv('../02 Data/Prepared Data/cleaned_products.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f5412-f9d9-459b-82ce-d14dbe543fec",
   "metadata": {},
   "source": [
    "# Verify saved files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fea1fbb5-975b-4b52-80b2-e8d914112fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders Data:\n",
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2398795        1    prior             2          3                  7   \n",
      "2    473747        1    prior             3          3                 12   \n",
      "3   2254736        1    prior             4          4                  7   \n",
      "4    431534        1    prior             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  \n",
      "0                     NaN  \n",
      "1                    15.0  \n",
      "2                    21.0  \n",
      "3                    29.0  \n",
      "4                    28.0   \n",
      "\n",
      "Products Data:\n",
      "   product_id                                       product_name  aisle_id  \\\n",
      "0           1                         Chocolate Sandwich Cookies        61   \n",
      "1           2                                   All-Seasons Salt       104   \n",
      "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
      "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
      "4           5                          Green Chile Anytime Sauce         5   \n",
      "\n",
      "   department_id  prices  \n",
      "0             19     5.8  \n",
      "1             13     9.3  \n",
      "2              7     4.5  \n",
      "3              1    10.5  \n",
      "4             13     4.3  \n"
     ]
    }
   ],
   "source": [
    "# Verify saved files (optional)\n",
    "df_orders_cleaned = pd.read_csv('../02 Data/Prepared Data/cleaned_orders.csv')\n",
    "df_prods_cleaned = pd.read_csv('../02 Data/Prepared Data/cleaned_products.csv')\n",
    "\n",
    "print(\"Orders Data:\")\n",
    "print(df_orders_cleaned.head(), \"\\n\")\n",
    "\n",
    "print(\"Products Data:\")\n",
    "print(df_prods_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb866b-ef8b-4068-ace0-2188b8b48726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
