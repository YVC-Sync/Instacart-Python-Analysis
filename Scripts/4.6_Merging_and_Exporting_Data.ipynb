{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc161a9-99c6-401b-bf08-ca1d4431502a",
   "metadata": {},
   "source": [
    "# Instacart Data Analysis: Merging and Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c4a6b-f6a6-4944-a6ef-e66f6987a3f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#1-Introduction)\n",
    "2. [Import Libraries](#2-Import-Libraries)\n",
    "3. [Load Data](#3-Load-Data)\n",
    "4. [Merge Data](#4-Merge-Data)\n",
    "   - 4.1 [Merge Orders and Orders_Products_Prior](#41-Merge-Orders-and-Orders_Products_Prior)\n",
    "   - 4.2 [Merge with Products Data](#42-Merge-with-Products-Data)\n",
    "5. [Export Data](#5-Export-Data)\n",
    "6. [Validate Export](#6-Validate-Export)\n",
    "7. [Conclusion](#7-Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2351c3a-14b5-4909-9f5c-cb6fcbd9197b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83efbc6e-0274-4fd3-bf80-80488e2146a3",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "In this notebook, I focused on **combining different Instacart datasets** into one **enriched dataset** for analysis. \n",
    "Here’s what I’ll be doing step by step:\n",
    "\n",
    "- Merging the `orders` and `orders_products_prior` dataframes to add product-level details to each order.\n",
    "- Combining that result with the cleaned `products` dataframe to include more product information.\n",
    "- Exporting the final merged dataset in a format that works best, like Pickle.\n",
    "- Double-checking everything to make sure it all lines up perfectly.\n",
    "\n",
    "The idea is to have all the **important data in one place** so I can dig into customer shopping habits and trends. I’ll also make sure the notebook is clean and **organized**, with clear comments and headings, so it’s easy to follow.\n",
    "\n",
    "**Goals:**\n",
    "1. Use the `merge()` function to combine data.\n",
    "2. Check if the merges worked using merge flags.\n",
    "3. Save the final datasets in the right formats.\n",
    "4. Keep the notebook neat, clear, and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad291c-3e21-4045-afbc-e14919e964f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d7ce8fd-a734-4828-b089-ef9eecb4ee32",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a60011-a5a8-4bb1-9b17-f970be583bfc",
   "metadata": {},
   "source": [
    "I imported **pandas** for handling dataframes, **numpy** for any calculations I might need, and **os** to make file paths easier to work with. I also included **matplotlib** and **seaborn** for visualizations, which I can use later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6a6678-6264-4786-a5e6-a9fb78756134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db1354b-025c-48aa-8e9d-04198d90ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: For visualizations or additional exports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afd393-8ede-4a2e-876e-49af364f4c08",
   "metadata": {},
   "source": [
    "##### Explanation:\n",
    "pandas (pd): For working with dataframes.\n",
    "\\\n",
    "numpy (np): For numerical operations.\n",
    "\\\n",
    "os: For handling file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69890b-c181-4176-89ef-4a978a14329b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f6c1840-0525-416d-bbd3-8b5f144ed0b6",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59dde6-467f-4741-b229-de9f0aa975c1",
   "metadata": {},
   "source": [
    "I loaded the **cleaned orders, products,** and `orders_products_prior` datasets to make sure I’m working with the **most up-to-date** and **accurate data**. I also used the `head()` **function** to double-check that each dataset was loaded correctly and everything looks as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ce86e88-a310-4fb9-bba0-271f0a303547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders DataFrame:\n",
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2398795        1    prior             2          3                  7   \n",
      "2    473747        1    prior             3          3                 12   \n",
      "3   2254736        1    prior             4          4                  7   \n",
      "4    431534        1    prior             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  \n",
      "0                     NaN  \n",
      "1                    15.0  \n",
      "2                    21.0  \n",
      "3                    29.0  \n",
      "4                    28.0  \n",
      "\n",
      "Products DataFrame:\n",
      "   product_id                                       product_name  aisle_id  \\\n",
      "0           1                         Chocolate Sandwich Cookies        61   \n",
      "1           2                                   All-Seasons Salt       104   \n",
      "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
      "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
      "4           5                          Green Chile Anytime Sauce         5   \n",
      "\n",
      "   department_id  prices  \n",
      "0             19     5.8  \n",
      "1             13     9.3  \n",
      "2              7     4.5  \n",
      "3              1    10.5  \n",
      "4             13     4.3  \n",
      "\n",
      "Orders_Products_Prior DataFrame Shape: (32434489, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load the orders_products_prior.csv file normally\n",
    "df_orders_prior = pd.read_csv(os.path.join(path, 'orders_products_prior.csv'))\n",
    "\n",
    "# Check the first few rows of each dataframe to confirm they loaded correctly\n",
    "print(\"Orders DataFrame:\")\n",
    "print(df_orders.head())\n",
    "\n",
    "print(\"\\nProducts DataFrame:\")\n",
    "print(df_products.head())\n",
    "\n",
    "print(\"\\nOrders_Products_Prior DataFrame Shape:\", df_orders_prior.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf13a4-30d5-4e04-9773-359e5a538986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6c85b7-e51e-43ce-8f2a-e489b50a8811",
   "metadata": {},
   "source": [
    "## 4. Merge Data\n",
    "### 4.1 Merge Orders and Orders_Products_Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32c5ad-3630-446b-8864-5f89758e03b3",
   "metadata": {},
   "source": [
    "This step **combined the orders** and `orders_products_prior` datasets so that I can link each order to its **product-level details**. I used an **inner merge** to make sure only **matching rows** are included, and I checked the **merge flags** and **shape** to confirm everything worked as planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6ff04ad-5f9c-416b-8044-df08036fa373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame Shape: (32434489, 11)\n",
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2539329        1    prior             1          2                  8   \n",
      "2   2539329        1    prior             1          2                  8   \n",
      "3   2539329        1    prior             1          2                  8   \n",
      "4   2539329        1    prior             1          2                  8   \n",
      "\n",
      "   days_since_prior_order  product_id  add_to_cart_order  reordered _merge  \n",
      "0                     NaN         196                  1          0   both  \n",
      "1                     NaN       14084                  2          0   both  \n",
      "2                     NaN       12427                  3          0   both  \n",
      "3                     NaN       26088                  4          0   both  \n",
      "4                     NaN       26405                  5          0   both  \n",
      "\n",
      "Merge Flag Counts:\n",
      "_merge\n",
      "both          32434489\n",
      "left_only            0\n",
      "right_only           0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge orders with orders_products_prior using 'order_id' as the key\n",
    "df_merged = df_orders.merge(df_orders_prior, on='order_id', how='inner', indicator=True)\n",
    "\n",
    "# Check the shape and preview the merged dataframe\n",
    "print(\"Merged DataFrame Shape:\", df_merged.shape)\n",
    "print(df_merged.head())\n",
    "\n",
    "# Check merge flag to confirm the success of the merge\n",
    "print(\"\\nMerge Flag Counts:\")\n",
    "print(df_merged['_merge'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ac4e1-3b27-4e06-8969-8861ccb400ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66bf7aa0-f21d-479f-af2e-fe35f86899c7",
   "metadata": {},
   "source": [
    "### 4.2 Merge with Products Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5f8d8-6207-4bb2-977a-5edb7c1a1a4f",
   "metadata": {},
   "source": [
    "Here, I merged the **combined dataset** with the **products data** to add product details like **names, departments, and prices.** This step is important for creating a dataset that’s ready for **in-depth analysis.** I double-checked the merge using **flags** to make sure the data lined up properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56c21fa5-c63b-4939-ae1d-7819692dd28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Merged DataFrame Shape: (32434212, 15)\n",
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2539329        1    prior             1          2                  8   \n",
      "2   2539329        1    prior             1          2                  8   \n",
      "3   2539329        1    prior             1          2                  8   \n",
      "4   2539329        1    prior             1          2                  8   \n",
      "\n",
      "   days_since_prior_order  product_id  add_to_cart_order  reordered  \\\n",
      "0                     NaN         196                  1          0   \n",
      "1                     NaN       14084                  2          0   \n",
      "2                     NaN       12427                  3          0   \n",
      "3                     NaN       26088                  4          0   \n",
      "4                     NaN       26405                  5          0   \n",
      "\n",
      "                              product_name  aisle_id  department_id  prices  \\\n",
      "0                                     Soda        77              7     9.0   \n",
      "1  Organic Unsweetened Vanilla Almond Milk        91             16    12.5   \n",
      "2                      Original Beef Jerky        23             19     4.4   \n",
      "3               Aged White Cheddar Popcorn        23             19     4.7   \n",
      "4         XL Pick-A-Size Paper Towel Rolls        54             17     1.0   \n",
      "\n",
      "  _merge  \n",
      "0   both  \n",
      "1   both  \n",
      "2   both  \n",
      "3   both  \n",
      "4   both  \n",
      "\n",
      "Merge Flag Counts:\n",
      "_merge\n",
      "both          32434212\n",
      "left_only            0\n",
      "right_only           0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop the _merge column from the previous merge to avoid conflicts\n",
    "df_merged.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "# Merge the merged dataframe with the products dataframe using 'product_id' as the key\n",
    "df_final = df_merged.merge(df_products, on='product_id', how='inner', indicator=True)\n",
    "\n",
    "# Check the shape and preview the final merged dataframe\n",
    "print(\"Final Merged DataFrame Shape:\", df_final.shape)\n",
    "print(df_final.head())\n",
    "\n",
    "# Check merge flag to confirm the success of the merge\n",
    "print(\"\\nMerge Flag Counts:\")\n",
    "print(df_final['_merge'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07305594-f42c-4e26-915a-efecad9de9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee005c99-cebb-4ad6-9e1c-851684260cce",
   "metadata": {},
   "source": [
    "## 5. Export Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3856bbf4-ea8b-4683-bc12-5ac92b988461",
   "metadata": {},
   "source": [
    "I exported the **final merged dataset** as a **pickle file** so it’s saved in a **compact format** that’s easy to load later. This way, I can jump straight into analysis without having to repeat these steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1536fb5a-8127-40db-9736-c5b720e8c182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Export the final merged dataframe to a pickle file\n",
    "df_final.to_pickle(os.path.join(path, 'orders_products_combined.pkl'))\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(\"Export completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737233cd-9a2c-46c3-9089-af4dae655166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1ea9fa-5bd9-41ea-9086-1ba9cb0d78fc",
   "metadata": {},
   "source": [
    "## 6. Validate Exported File\n",
    "\n",
    "In this section, I re-import the exported `orders_products_combined.pkl` file to confirm that it was saved correctly and the shape matches the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d79065-1bb2-4058-aa62-2b22abed4ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported DataFrame Shape: (32434212, 15)\n",
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2539329        1    prior             1          2                  8   \n",
      "2   2539329        1    prior             1          2                  8   \n",
      "3   2539329        1    prior             1          2                  8   \n",
      "4   2539329        1    prior             1          2                  8   \n",
      "\n",
      "   days_since_prior_order  product_id  add_to_cart_order  reordered  \\\n",
      "0                     NaN         196                  1          0   \n",
      "1                     NaN       14084                  2          0   \n",
      "2                     NaN       12427                  3          0   \n",
      "3                     NaN       26088                  4          0   \n",
      "4                     NaN       26405                  5          0   \n",
      "\n",
      "                              product_name  aisle_id  department_id  prices  \\\n",
      "0                                     Soda        77              7     9.0   \n",
      "1  Organic Unsweetened Vanilla Almond Milk        91             16    12.5   \n",
      "2                      Original Beef Jerky        23             19     4.4   \n",
      "3               Aged White Cheddar Popcorn        23             19     4.7   \n",
      "4         XL Pick-A-Size Paper Towel Rolls        54             17     1.0   \n",
      "\n",
      "  _merge  \n",
      "0   both  \n",
      "1   both  \n",
      "2   both  \n",
      "3   both  \n",
      "4   both  \n"
     ]
    }
   ],
   "source": [
    "# Validating the exported file is critical to ensure the data was saved and can be loaded back correctly.\n",
    "# This step confirms that no issues occurred during the export process, preserving data integrity for future analysis.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import the exported pickle file\n",
    "df_combined_check = pd.read_pickle(r\"D:/YVC/Data Analytics (CF)/Python Fundamentals for Data Analysts/Instacart Basket Analysis/02 Data/Original Data/orders_products_combined.pkl\")\n",
    "\n",
    "# Check the shape of the imported DataFrame\n",
    "print(\"Imported DataFrame Shape:\", df_combined_check.shape)\n",
    "\n",
    "# Optionally, display the first few rows to confirm successful import\n",
    "print(df_combined_check.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77588199-2acb-4ac8-9639-5a2d5e3f61e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a32e156-c265-4e7f-899e-56b50cbcd7ba",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "In this notebook, I brought together multiple Instacart datasets into a single enriched file, ensuring that the data is both clean and ready for analysis. These steps not only streamlined the data but also set the stage for analyzing customer behavior and uncovering trends. With the final dataset verified and exported successfully, I’m ready to dive deeper into the data and generate actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392166b2-c434-4b22-9b31-a665039025da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
