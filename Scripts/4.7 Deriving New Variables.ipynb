{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d6ddfa-d491-42e6-bae4-6718b6b1ea24",
   "metadata": {},
   "source": [
    "# 4.7 Deriving New Variables\n",
    "\n",
    "## Table of Contents\n",
    "1. Introduction\n",
    "2. Import Libraries\n",
    "3. Load Data\n",
    "4. Derive New Variables\n",
    "    - 4.1 Create the \"price_label\" Column\n",
    "    - 4.2 Create the \"busiest_day\" Column\n",
    "    - 4.3 Update \"busiest_day\" to Include Two Busiest and Least Busy Days\n",
    "    - 4.4 Add the 'order_hour_of_day' Column\n",
    "    - 4.5 Create the \"busiest_period_of_day\" Column\n",
    "5. Consistency Checks\n",
    "6. Verify Data and Export\n",
    "7. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055ac85-ecda-4aa2-8a1b-ae666b2c9e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de3babcf-2c48-406c-a3bc-c0161552ce7a",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "In this notebook, I focused on creating new variables for the Instacart dataset to get more insights into customer behavior. These new variables are great for spotting trends, breaking down data into useful segments, and making future analysis smoother and faster.\n",
    "\n",
    "### Goals:\n",
    "- Categorize products based on their price range.\n",
    "- Identify the busiest and least busy days for ordering.\n",
    "- Break the day into segments to show which hours are busiest, least busy, or somewhere in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ca818-7ae6-45e8-98f8-216965615fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e9913aa-fe28-4899-a602-54861ef2c68c",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "To get started, I imported the libraries I needed to work with the data. These are: \n",
    "- pandas: For working with the dataset and manipulating data. \n",
    "- numpy: For anything that requires number-crunching or calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd66589b-ec80-4fc1-ade9-3d9464792536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries I need\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ff7051f-4be0-4128-87ed-0a033a6327b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  product_id  add_to_cart_order  reordered           product_name  \\\n",
      "0         2       33120                  1          1     Organic Egg Whites   \n",
      "1         2       28985                  2          1  Michigan Organic Kale   \n",
      "2         2        9327                  3          0          Garlic Powder   \n",
      "3         2       45918                  4          1         Coconut Butter   \n",
      "4         2       30035                  5          0      Natural Sweetener   \n",
      "\n",
      "   aisle_id  department_id  prices  \n",
      "0        86             16    11.3  \n",
      "1        83              4    13.4  \n",
      "2       104             13     3.6  \n",
      "3        19             13     8.4  \n",
      "4        17             13    13.7  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using a raw string (r\"\")\n",
    "merged_orders_products = pd.read_csv(r\"D:\\YVC\\Data Analytics (CF)\\Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\merged_orders_products.csv\")\n",
    "\n",
    "# Check the first few rows\n",
    "print(merged_orders_products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fb9ef-ab28-4bdd-bbd4-e31003c95b11",
   "metadata": {},
   "source": [
    "## 3. Load the Data\n",
    "Next, I loaded the `merged_orders_products.csv` dataset. This dataset combines orders and product details, which makes it perfect for the kind of analysis I want to do. I also double-checked that it loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cafae42b-d3b8-4cac-b6bc-625563664d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  product_id  add_to_cart_order  reordered           product_name  \\\n",
      "0         2       33120                  1          1     Organic Egg Whites   \n",
      "1         2       28985                  2          1  Michigan Organic Kale   \n",
      "2         2        9327                  3          0          Garlic Powder   \n",
      "3         2       45918                  4          1         Coconut Butter   \n",
      "4         2       30035                  5          0      Natural Sweetener   \n",
      "\n",
      "   aisle_id  department_id  prices  \n",
      "0        86             16    11.3  \n",
      "1        83              4    13.4  \n",
      "2       104             13     3.6  \n",
      "3        19             13     8.4  \n",
      "4        17             13    13.7  \n"
     ]
    }
   ],
   "source": [
    "# Load the merged orders-products data from the specified file path\n",
    "merged_orders_products = pd.read_csv(r'D:\\YVC\\Data Analytics (CF)\\Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\merged_orders_products.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe to confirm successful loading\n",
    "print(merged_orders_products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47f186-0ec2-4f1c-a2ce-30afd561775d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25f014a-d306-498f-b467-47e9cd29b324",
   "metadata": {},
   "source": [
    "## 4. Derive New Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b353e96-ca06-4bb0-884c-6d63f2e7bba2",
   "metadata": {},
   "source": [
    "### 4.1 Create the \"price_label\" Column\n",
    "\n",
    "Here, I created a column called `\"price_label\"` to group products into categories: **Low-range, Mid-range,** or **High-range,** depending on their price. This helps give more context to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98a5bccd-8b06-467c-9a00-ed085d9659b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prices        price_label\n",
      "0    11.3  Mid-range product\n",
      "1    13.4  Mid-range product\n",
      "2     3.6  Low-range product\n",
      "3     8.4  Mid-range product\n",
      "4    13.7  Mid-range product\n"
     ]
    }
   ],
   "source": [
    "# Create a new column \"price_label\" based on the price range\n",
    "# - Low-range product: prices <= 5\n",
    "# - Mid-range product: 5 < prices <= 15\n",
    "# - High-range product: prices > 15\n",
    "merged_orders_products['price_label'] = merged_orders_products['prices'].apply(\n",
    "    lambda x: 'Low-range product' if x <= 5 else ('Mid-range product' if x <= 15 else 'High-range product')\n",
    ")\n",
    "\n",
    "# Check the first few rows to ensure the new column is created\n",
    "print(merged_orders_products[['prices', 'price_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c517c4-0842-4ff6-8845-ed24181b46c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb2e39b9-e7c7-4a74-b026-fe97ede10190",
   "metadata": {},
   "source": [
    "### 4.2 Create the \"busiest_day\" Column\n",
    "Next, I added a column to classify each day of the week as Busiest day, Least busy, or Regularly busy, based on the `order_dow` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c080d0bb-d921-423a-9571-67087a251aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  product_id  add_to_cart_order  reordered           product_name  \\\n",
      "0         2       33120                  1          1     Organic Egg Whites   \n",
      "1         2       28985                  2          1  Michigan Organic Kale   \n",
      "2         2        9327                  3          0          Garlic Powder   \n",
      "3         2       45918                  4          1         Coconut Butter   \n",
      "4         2       30035                  5          0      Natural Sweetener   \n",
      "\n",
      "   aisle_id  department_id  prices        price_label  order_dow  \n",
      "0        86             16    11.3  Mid-range product          5  \n",
      "1        83              4    13.4  Mid-range product          5  \n",
      "2       104             13     3.6  Low-range product          5  \n",
      "3        19             13     8.4  Mid-range product          5  \n",
      "4        17             13    13.7  Mid-range product          5  \n",
      "   order_dow     busiest_day\n",
      "0          5  Regularly busy\n",
      "1          5  Regularly busy\n",
      "2          5  Regularly busy\n",
      "3          5  Regularly busy\n",
      "4          5  Regularly busy\n"
     ]
    }
   ],
   "source": [
    "# Load the orders.csv file to access order-related details\n",
    "orders = pd.read_csv(r'D:\\YVC\\Data Analytics (CF)\\Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Original Data\\orders.csv')\n",
    "\n",
    "# Merge the 'order_dow' column from the orders data into the merged_orders_products dataframe\n",
    "# This is needed to determine the busiest days of the week\n",
    "merged_orders_products = merged_orders_products.merge(\n",
    "    orders[['order_id', 'order_dow']],  # Selecting only relevant columns\n",
    "    on='order_id',  # Merging based on 'order_id'\n",
    "    how='left'  # Keeping all rows from merged_orders_products\n",
    ")\n",
    "\n",
    "# Confirm that the 'order_dow' column has been successfully added\n",
    "print(merged_orders_products.head())\n",
    "\n",
    "# Create a new column \"busiest_day\" to classify the day as:\n",
    "# - 'Busiest day': order_dow == 0\n",
    "# - 'Least busy': order_dow == 4\n",
    "# - 'Regularly busy': all other days\n",
    "merged_orders_products['busiest_day'] = merged_orders_products['order_dow'].apply(\n",
    "    lambda x: 'Busiest day' if x == 0 else ('Least busy' if x == 4 else 'Regularly busy')\n",
    ")\n",
    "\n",
    "# Check the first few rows to confirm the column has been added\n",
    "print(merged_orders_products[['order_dow', 'busiest_day']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff6f4c-a52d-4820-8a9b-53c42bb05343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6db2fe2f-0540-4275-b104-d7cfd2ee4b7b",
   "metadata": {},
   "source": [
    "### 4.3 Update \"busiest_day\" to Include Two Busiest and Least Busy Days\n",
    "To get a clearer picture, I expanded the `\"busiest_day\"` column to show **two busiest** and **two least busy days,** instead of just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94924049-fd58-4b2e-8cc0-b7ef19b4843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_dow     busiest_days\n",
      "0          5  Least busy days\n",
      "1          5  Least busy days\n",
      "2          5  Least busy days\n",
      "3          5  Least busy days\n",
      "4          5  Least busy days\n"
     ]
    }
   ],
   "source": [
    "# \"busiest_day\"column to include:\n",
    "# - **Busiest days**: Days 0 and 1\n",
    "# - **Least busy days**: Days 4 and 5\n",
    "# - **Regularly busy**: All other days\n",
    "\n",
    "# Update \"busiest_day\" to include two busiest and two least busy days\n",
    "merged_orders_products['busiest_days'] = merged_orders_products['order_dow'].apply(\n",
    "    lambda x: 'Busiest days' if x in [0, 1] else ('Least busy days' if x in [4, 5] else 'Regularly busy')\n",
    ")\n",
    "\n",
    "# Check the first few rows to confirm the updated column\n",
    "print(merged_orders_products[['order_dow', 'busiest_days']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9d425-56d6-404d-bc9c-79812ff831a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84ce8e3a-ee29-41b4-ac06-89873ac60ca2",
   "metadata": {},
   "source": [
    "### 4.4 Add the 'order_hour_of_day' Column\n",
    "Here, I merged the `order_hour_of_day` column from the orders dataset so I could analyze the busiest hours of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1be2319-b845-489c-8445-31ff88ac7c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  product_id  add_to_cart_order  reordered           product_name  \\\n",
      "0         2       33120                  1          1     Organic Egg Whites   \n",
      "1         2       28985                  2          1  Michigan Organic Kale   \n",
      "2         2        9327                  3          0          Garlic Powder   \n",
      "3         2       45918                  4          1         Coconut Butter   \n",
      "4         2       30035                  5          0      Natural Sweetener   \n",
      "\n",
      "   aisle_id  department_id  prices        price_label  order_dow  \\\n",
      "0        86             16    11.3  Mid-range product          5   \n",
      "1        83              4    13.4  Mid-range product          5   \n",
      "2       104             13     3.6  Low-range product          5   \n",
      "3        19             13     8.4  Mid-range product          5   \n",
      "4        17             13    13.7  Mid-range product          5   \n",
      "\n",
      "      busiest_day     busiest_days  order_hour_of_day  \n",
      "0  Regularly busy  Least busy days                  9  \n",
      "1  Regularly busy  Least busy days                  9  \n",
      "2  Regularly busy  Least busy days                  9  \n",
      "3  Regularly busy  Least busy days                  9  \n",
      "4  Regularly busy  Least busy days                  9  \n"
     ]
    }
   ],
   "source": [
    "# Add the 'order_hour_of_day' column from orders.csv\n",
    "merged_orders_products = merged_orders_products.merge(\n",
    "    orders[['order_id', 'order_hour_of_day']],\n",
    "    on='order_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check if the column is now included\n",
    "print(merged_orders_products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15fe470-1d2f-464e-9bf8-06768110750b",
   "metadata": {},
   "source": [
    "### 4.5 Create the \"busiest_period_of_day\" Column\n",
    "Finally, I used the `order_hour_of_day` column to divide the day into three time categories: **Most orders, Fewest orders,** and **Average orders.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "186d6329-8b41-4434-96ce-ca58cb16313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_hour_of_day busiest_period_of_day\n",
      "0                  9        Average orders\n",
      "1                  9        Average orders\n",
      "2                  9        Average orders\n",
      "3                  9        Average orders\n",
      "4                  9        Average orders\n"
     ]
    }
   ],
   "source": [
    "#Categorize the time of day into:\n",
    "# - **Most orders**: 10 AM to 4 PM\n",
    "# - **Fewest orders**: Before 8 AM or after 8 PM\n",
    "# - **Average orders**: All other times\n",
    "\n",
    "# Create the \"busiest_period_of_day\" column based on order_hour_of_day\n",
    "merged_orders_products['busiest_period_of_day'] = merged_orders_products['order_hour_of_day'].apply(\n",
    "    lambda x: 'Most orders' if 10 <= x <= 16 else ('Fewest orders' if x < 8 or x > 20 else 'Average orders')\n",
    ")\n",
    "\n",
    "# Check the first few rows to confirm the new column is created\n",
    "print(merged_orders_products[['order_hour_of_day', 'busiest_period_of_day']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0380553-d07a-4401-8f46-1dc5ba01c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_hour_of_day_y busiest_period_of_day\n",
      "0                    9        Average orders\n",
      "1                    9        Average orders\n",
      "2                    9        Average orders\n",
      "3                    9        Average orders\n",
      "4                    9        Average orders\n"
     ]
    }
   ],
   "source": [
    "# Create the \"busiest_period_of_day\" column based on 'order_hour_of_day_y'\n",
    "merged_orders_products['busiest_period_of_day'] = merged_orders_products['order_hour_of_day_y'].apply(\n",
    "    lambda x: 'Most orders' if 10 <= x <= 16 else ('Fewest orders' if x < 8 or x > 20 else 'Average orders')\n",
    ")\n",
    "\n",
    "# Check if the new column has been created successfully\n",
    "print(merged_orders_products[['order_hour_of_day_y', 'busiest_period_of_day']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152c8fe-d228-4a0a-b56f-3b8a7e834d53",
   "metadata": {},
   "source": [
    "## 5. Consistency Checks\n",
    "Before exporting the data, it’s super important to make sure everything checks out. I’m running some quick consistency checks to catch any missing values and confirm the data types for each column. This step helps ensure the data is clean and ready for analysis, avoiding any surprises later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7c06550c-1dc5-44b2-909d-e638a6f9af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                     0\n",
      "product_id                   0\n",
      "add_to_cart_order            0\n",
      "reordered                    0\n",
      "product_name             28171\n",
      "aisle_id                     0\n",
      "department_id                0\n",
      "prices                       0\n",
      "price_label                  0\n",
      "order_dow                    0\n",
      "busiest_day                  0\n",
      "order_hour_of_day_x          0\n",
      "order_hour_of_day_y          0\n",
      "order_hour_of_day            0\n",
      "busiest_period_of_day        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "print(merged_orders_products.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5dd88271-7a36-4dec-a3fe-c5247ac02d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                   int64\n",
      "product_id                 int64\n",
      "add_to_cart_order          int64\n",
      "reordered                  int64\n",
      "product_name              object\n",
      "aisle_id                   int64\n",
      "department_id              int64\n",
      "prices                   float64\n",
      "price_label               object\n",
      "order_dow                  int64\n",
      "busiest_day               object\n",
      "order_hour_of_day_x        int64\n",
      "order_hour_of_day_y        int64\n",
      "order_hour_of_day          int64\n",
      "busiest_period_of_day     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of all columns\n",
    "print(merged_orders_products.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c14e9-1fa6-48bf-be0e-426eeae8d75b",
   "metadata": {},
   "source": [
    "##### Output:\n",
    "This will highlight if there are any missing values and confirm the data types are as expected. It’s a quick way to make sure the dataset is good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9ea7b-988c-4df2-9b26-774c307c995b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f539cd-2fd3-4a4d-bd15-e2df37bec908",
   "metadata": {},
   "source": [
    "## 6. Verify Data and Export\n",
    "Before exporting the data, I verified that the new columns looked correct. Then, I saved the updated dataset as a pickle file for efficient storage and future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c898b824-ea94-4677-a813-89d3283b373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busiest_period_of_day\n",
      "Most orders       18680601\n",
      "Average orders    10140386\n",
      "Fewest orders      3613225\n",
      "Name: count, dtype: int64\n",
      "Data exported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Verify the new column values\n",
    "print(merged_orders_products['busiest_period_of_day'].value_counts())\n",
    "\n",
    "# Export the dataframe as a pickle file\n",
    "merged_orders_products.to_pickle(r'D:\\YVC\\Data Analytics (CF)\\Python Fundamentals for Data Analysts\\Instacart Basket Analysis\\02 Data\\Prepared Data\\merged_orders_products_updated.pkl')\n",
    "print(\"Data exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76218d-408d-4918-9064-9e77092dee9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f49f778b-7184-4b7a-9573-f100151d280a",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "In this notebook, I created several new variables to make the Instacart data more insightful. These new variables help with segmenting data based on price, busy days, and periods of the day. With this cleaner, more detailed dataset, I’m ready to dive deeper into customer behavior and improve future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcab840-39eb-4bed-826d-c7bcd707a670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
